{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50174a58",
   "metadata": {},
   "source": [
    "# Hierarchical Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302ff87",
   "metadata": {},
   "source": [
    "## What is Matrix Factorization? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dba218",
   "metadata": {},
   "source": [
    "Matrix factorization is a dimensionality reduction technique which can be expressed as the following general optimization problem:\n",
    "\n",
    "$$ \\min_{\\textbf{U}, \\textbf{V}} \\quad \\mathcal{L} \\ \\big( \\ \\textbf{X}, \\textbf{U} \\textbf{V}^\\top \\ \\big) $$\n",
    "\n",
    "where:\n",
    "\n",
    "$\n",
    "\\begin{aligned} \n",
    "\\quad\\textbf{X} & \\quad \\text{is an} \\  m \\times n \\ \\text{input matrix}, \\\\\n",
    "\\quad\\textbf{U} & \\quad \\text{is an} \\  m \\text{-row output matrix}, \\\\\n",
    "\\quad\\textbf{V} & \\quad \\text{is an} \\  n \\text{-row output matrix}, \\\\\n",
    "\\quad\\mathcal{L} & \\quad \\text{is a loss function}. \n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "The input matrix is typically very sparse: most of the elements $x_{i,j}, \\ i \\in \\{1, \\dots, m \\}, \\ j \\in \\{1, \\dots, n \\}$ are empty. The information that *is* contained in the input matrix is encoded in a latent space by the product of the output matrices. The column dimension of the output can be denoted by $k$ where $k \\ll \\{m, n\\}$. The choice of loss function is dependent upon the problem space represented by the input matrix.\n",
    "\n",
    "This technique has a variety of practical applications. Matrix factorization was used by the winners of the famous [Netlix Prize](https://en.wikipedia.org/wiki/Netflix_Prize) and is commonly referred to as *collaborative filtering* in the recommendation system domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4a78a",
   "metadata": {},
   "source": [
    "## What is Hierarchical Matrix Factorization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e1d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b926dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2761, 0.6389, 0.5799, 0.1393, 0.7162])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6275b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed02cbd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
